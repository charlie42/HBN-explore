{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4128d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_FROM_FILE = 0\n",
    "IMPORTANCES_FROM_FILE = 0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, recall_score, precision_score, balanced_accuracy_score, f1_score, roc_auc_score, fbeta_score, make_scorer, roc_curve, precision_recall_curve, accuracy_score, r2_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "    \n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "\n",
    "data_intermediate_dir = \"data/intermediate/\"\n",
    "item_lvl_wo_imp = pd.read_csv(data_intermediate_dir + \"item_lvl_wo_impairment.csv\")\n",
    "\n",
    "# Prepare input and ouptut column names\n",
    "\n",
    "output_cols = [x for x in item_lvl_wo_imp.columns if x.startswith(\"WHODAS\") or x.startswith(\"CIS\")] # All impairment columns\n",
    "\n",
    "input_cols = [x for x in item_lvl_wo_imp.columns if \n",
    "                       not x.startswith(\"Diag: \") \n",
    "                       and not x.startswith(\"WIAT\")\n",
    "                       and not x.startswith(\"WISC\")\n",
    "                       and not x.startswith(\"WHODAS\")\n",
    "                       and not x.startswith(\"CIS\")] # Input columns are all columns except Diagnosis, WIAT, and WISC, impairment columns\n",
    "\n",
    "# Separate test set for all impairment scores\n",
    "\n",
    "# Shuffle the dataset \n",
    "shuffle_df = item_lvl_wo_imp.sample(frac=1, random_state=42)\n",
    "\n",
    "# Define a size for the train set \n",
    "train_size = int(0.7 * len(item_lvl_wo_imp))\n",
    "\n",
    "# Split the dataset \n",
    "train_set = shuffle_df[:train_size]\n",
    "test_set = shuffle_df[train_size:] # Don't touch this until the end\n",
    "\n",
    "# Train_train and Validation set\n",
    "# Define a size for your train_train set \n",
    "train_train_size = int(0.7 * len(train_set))\n",
    "\n",
    "# Split your dataset \n",
    "train_train_set = train_set[:train_train_size]\n",
    "val_set = train_set[train_train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be13ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_models_and_param_grids():\n",
    "    \n",
    "    # Define base models\n",
    "    dt = DecisionTreeRegressor()\n",
    "    rf = RandomForestRegressor()\n",
    "    svr = svm.SVR()\n",
    "    en = ElasticNet()\n",
    "    \n",
    "    # Impute missing values\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "    \n",
    "    # Standardize data\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Make pipelines\n",
    "    dt_pipe = make_pipeline(imputer, scaler, dt)\n",
    "    rf_pipe = make_pipeline(imputer, scaler, rf)\n",
    "    svr_pipe = make_pipeline(imputer, scaler, svr)\n",
    "    en_pipe = make_pipeline(imputer, scaler, en)\n",
    "    \n",
    "    # Define parameter grids to search for each pipe\n",
    "    from scipy.stats import loguniform, uniform\n",
    "    dt_param_grid = {\n",
    "        \"decisiontreeregressor__splitter\": [\"best\",\"random\"],\n",
    "        \"decisiontreeregressor__min_samples_split\": np.random.randint(2, 20, 30),\n",
    "        \"decisiontreeregressor__max_depth\": np.random.randint(1, 30, 30),\n",
    "        \"decisiontreeregressor__min_samples_leaf\": np.random.randint(1, 20, 30),\n",
    "        \"decisiontreeregressor__max_leaf_nodes\": np.random.randint(2, 50, 30)\n",
    "    }\n",
    "    rf_param_grid = {\n",
    "        'randomforestregressor__max_depth' : np.random.randint(5, 150, 30),\n",
    "        'randomforestregressor__min_samples_split': np.random.randint(2, 50, 30),\n",
    "        'randomforestregressor__n_estimators': np.random.randint(50, 400, 10),\n",
    "        'randomforestregressor__min_samples_leaf': np.random.randint(1, 20, 30),\n",
    "        'randomforestregressor__max_features': ['auto', 'sqrt', 'log2', 0.25, 0.5, 0.75, 1.0]\n",
    "    }\n",
    "    svr_param_grid = {\n",
    "        'svr__C': loguniform(1e-03, 1e+02),\n",
    "        'svr__gamma': loguniform(1e-03, 1e+02),\n",
    "        'svr__degree': uniform(2, 5),\n",
    "        'svr__epsilon': loguniform(1e-03,1),\n",
    "        'svr__kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "    en_param_grid = {\n",
    "        'elasticnet__alpha': loguniform(1e-5, 100),\n",
    "        'elasticnet__l1_ratio': uniform(0, 1)\n",
    "    }\n",
    "    \n",
    "    base_models_and_param_grids = [\n",
    "        (dt_pipe, dt_param_grid),\n",
    "        (rf_pipe, rf_param_grid),\n",
    "        (svr_pipe, svr_param_grid),\n",
    "        #(en_pipe, en_param_grid),\n",
    "    ]\n",
    "    \n",
    "    return base_models_and_param_grids\n",
    "\n",
    "def get_best_classifier(base_model, grid, output_col):\n",
    "    rs = RandomizedSearchCV(estimator=base_model, param_distributions=grid, cv=3, scoring=\"r2\", n_iter=100, n_jobs = -1)\n",
    "    \n",
    "    rs.fit(train_set[input_cols], train_set[output_col]) # On train_set, not train_train_set because do cross-validation\n",
    "    \n",
    "    best_estimator = rs.best_estimator_\n",
    "    best_score = rs.best_score_\n",
    "    \n",
    "    # If chosen model is SVM add a predict_proba parameter (not needed for grid search, and slows it down significantly)\n",
    "    if 'svc' in best_estimator.named_steps.keys():\n",
    "        best_estimator.set_params(svc__probability=True)\n",
    "\n",
    "    return (best_estimator, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "208d0376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_estimator_for_output(output_col):\n",
    "    best_score = 0\n",
    "    best_classifier = None\n",
    "    base_models_and_param_grids = get_base_models_and_param_grids()\n",
    "    for (base_model, grid) in base_models_and_param_grids:\n",
    "        best_classifier_for_model, best_score_for_model = get_best_classifier(base_model, grid, output_col)\n",
    "        if best_score_for_model > best_score:\n",
    "            best_classifier = best_classifier_for_model\n",
    "            best_score = best_score_for_model\n",
    "    return best_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "725b737c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/63/96f7chcx7qq5r9fq4x0x72bw0000gq/T/ipykernel_8190/2317245052.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mbest_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_cols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbest_estimator_for_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_best_estimator_for_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mbest_estimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_estimator_for_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best estimator for \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\": \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_estimators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/63/96f7chcx7qq5r9fq4x0x72bw0000gq/T/ipykernel_8190/574807982.py\u001b[0m in \u001b[0;36mfind_best_estimator_for_output\u001b[0;34m(output_col)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbase_models_and_param_grids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_base_models_and_param_grids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_models_and_param_grids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbest_classifier_for_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_score_for_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_best_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_col\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbest_score_for_model\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mbest_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_classifier_for_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/63/96f7chcx7qq5r9fq4x0x72bw0000gq/T/ipykernel_8190/2963627712.py\u001b[0m in \u001b[0;36mget_best_classifier\u001b[0;34m(base_model, grid, output_col)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"r2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# On train_set, not train_train_set because do cross-validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mbest_estimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1765\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[1;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if MODELS_FROM_FILE == 0:\n",
    "    best_estimators = {}\n",
    "    for output in output_cols:\n",
    "        best_estimator_for_output = find_best_estimator_for_output(output)\n",
    "        best_estimators[output] = best_estimator_for_output\n",
    "        print(\"Best estimator for \", output, \": \", best_estimators[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7976b907",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['r2']   \n",
    "def get_metrics(estimator, output_col, input_cols, validation_or_test = \"validation\", print_output_flag = 0):\n",
    "    input_cols = input_cols\n",
    "    \n",
    "    if validation_or_test == \"test\":\n",
    "        x = test_set[input_cols]\n",
    "        y = test_set[output_col]\n",
    "    else: \n",
    "        x = val_set[input_cols]\n",
    "        y = val_set[output_col]\n",
    "        \n",
    "    y_pred = estimator.predict(x)\n",
    "    \n",
    "    metrics = []\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    metrics.append(r2)\n",
    "    \n",
    "    if print_output_flag:\n",
    "        print(output_col)\n",
    "        print(\"r2: \", r2)\n",
    "        \n",
    "        plt.scatter(y, y_pred)\n",
    "        plt.show()\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2406557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check cross-validation performance of the final model on validation set for all models\n",
    "def plot_test_vs_train_scores(cv_results):\n",
    "    scores = pd.DataFrame(cv_results)[[\"test_score\", \"train_score\"]]\n",
    "    display(scores)\n",
    "    scores.plot.hist(bins=50, edgecolor=\"black\")\n",
    "    plt.show()\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "results_val_set = []\n",
    "for output in output_cols:\n",
    "    if output == \"WHODAS_P,WHODAS_P_Total\":\n",
    "        estimator = Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
    "                ('standardscaler', StandardScaler()),\n",
    "                ('randomforestregressor',\n",
    "                 RandomForestRegressor(max_depth=21, max_features=0.5,\n",
    "                                       min_samples_split=4,\n",
    "                                       n_estimators=319))])\n",
    "        cv_results = cross_validate(estimator, train_set[input_cols], train_set[output], return_train_score = True)\n",
    "        metrics = [np.mean(cv_results[\"test_score\"]), np.std(cv_results[\"test_score\"])]\n",
    "        results_val_set.append([\n",
    "            output, \n",
    "            *metrics])\n",
    "\n",
    "        plot_test_vs_train_scores(cv_results)\n",
    "    if output == \"CIS_P,CIS_P_Score\":\n",
    "        estimator = Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n",
    "                ('standardscaler', StandardScaler()),\n",
    "                ('svr',\n",
    "                 SVR(C=0.0026061817823488996, degree=2.9276653647992723,\n",
    "                     epsilon=0.16120893756532528, gamma=1.0258809033610814,\n",
    "                     kernel='linear'))])\n",
    "        cv_results = cross_validate(estimator, train_set[input_cols], train_set[output], return_train_score = True)\n",
    "        metrics = [np.mean(cv_results[\"test_score\"]), np.std(cv_results[\"test_score\"])]\n",
    "        results_val_set.append([\n",
    "            output, \n",
    "            *metrics])\n",
    "\n",
    "        plot_test_vs_train_scores(cv_results)\n",
    "restults_val_set_df = pd.DataFrame(results_val_set, columns=[\"Output\"] + [\"Mean R2\", \"Std R2\"])\n",
    "restults_val_set_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
